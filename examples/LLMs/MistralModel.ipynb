{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Using the Swarmauri Package Components**\n",
    "\n",
    "This guide demonstrates how to use various components of the Swarmauri package, including the `MistralModel`, `Conversation`, and message classes such as `HumanMessage`, `SystemMessage`. These examples will guide you through the setup and utilization of these components for common tasks.\n",
    "\n",
    "## **Setup**\n",
    "\n",
    "Before using the components, ensure you have the necessary API keys set up as environment variables. In this case, you'll need the `MISTRAL_API_KEY` for initializing the `MistralModel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "import os\n",
    "from swarmauri.standard.llms.concrete.MistralModel import MistralModel as LLM\n",
    "from swarmauri.standard.conversations.concrete.Conversation import Conversation\n",
    "\n",
    "from swarmauri.standard.messages.concrete.AgentMessage import AgentMessage\n",
    "from swarmauri.standard.messages.concrete.HumanMessage import HumanMessage\n",
    "from swarmauri.standard.messages.concrete.SystemMessage import SystemMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Unit Test: `test_ubc_resource`**\n",
    "\n",
    "This unit test verifies that the `MistralModel`  is initialized correctly and that its `resource` attribute is set to `'LLM'`. This is important to ensure that the model is correctly identified when used within your applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.unit\n",
    "def test_ubc_resource():\n",
    "    API_KEY = os.getenv('MISTRAL_API_KEY')\n",
    "    llm = LLM(api_key = API_KEY)\n",
    "    assert llm.resource == 'LLM'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Unit Test: `test_ubc_type`**\n",
    "\n",
    "This unit test ensures that the `MistralModel`  is correctly initialized and that its `type` attribute is set to `'MistralModel'`. This check is essential to verify that the model is recognized by its specific class name within the SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.unit\n",
    "def test_ubc_type():\n",
    "    API_KEY = os.getenv('MISTRAL_API_KEY')\n",
    "    llm = LLM(api_key = API_KEY)\n",
    "    assert llm.type == 'MistralModel'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Unit Test: `test_serialization`**\n",
    "\n",
    "This unit test checks the serialization and deserialization process for the `MistralModel` . It ensures that the model's state can be accurately converted to a JSON format and then restored back to an object without losing any data. This is crucial for scenarios where the model's state needs to be saved and loaded, such as in persistent storage or data transfer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.unit\n",
    "def test_serialization():\n",
    "    API_KEY = os.getenv('MISTRAL_API_KEY')\n",
    "    llm = LLM(api_key = API_KEY)\n",
    "    assert llm.id == LLM.model_validate_json(llm.model_dump_json()).id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Unit Test: `test_default_name`**\n",
    "\n",
    "This unit test verifies that the `MistralModel`  is initialized with the correct default name. Ensuring that the model has the correct default name is important for consistency and for identifying the model version being used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.unit\n",
    "def test_default_name():\n",
    "    API_KEY = os.getenv('MISTRAL_API_KEY')\n",
    "    model = LLM(api_key = API_KEY)\n",
    "    assert model.name == 'open-mixtral-8x7b'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit Test: `test_no_system_context`\n",
    "\n",
    "This unit test ensures that the `MistralModel`  can generate a prediction in a conversation without any predefined system context. It checks that the model's response is of the correct type, verifying basic functionality in a conversational setup.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.unit\n",
    "def test_no_system_context():\n",
    "    API_KEY = os.getenv('MISTRAL_API_KEY')\n",
    "    model = LLM(api_key = API_KEY)\n",
    "    conversation = Conversation()\n",
    "\n",
    "    input_data = \"Hello\"\n",
    "    human_message = HumanMessage(content=input_data)\n",
    "    conversation.add_message(human_message)\n",
    "\n",
    "    model.predict(conversation=conversation)\n",
    "    prediction = conversation.get_last().content\n",
    "    assert type(prediction) == str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Acceptance Test: `test_nonpreamble_system_context`**\n",
    "\n",
    "This acceptance test checks how the `MistralModel`  responds when a system context is introduced mid-conversation. Specifically, it verifies that the model adheres to the system instruction provided and incorporates it into its subsequent responses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.acceptance\n",
    "def test_nonpreamble_system_context():\n",
    "    API_KEY = os.getenv('MISTRAL_API_KEY')\n",
    "    model = LLM(api_key = API_KEY)\n",
    "    conversation = Conversation()\n",
    "\n",
    "    # Say hi\n",
    "    input_data = \"Hi\"\n",
    "    human_message = HumanMessage(content=input_data)\n",
    "    conversation.add_message(human_message)\n",
    "\n",
    "    # Get Prediction\n",
    "    prediction = model.predict(conversation=conversation)\n",
    "\n",
    "    # Give System Context\n",
    "    system_context = 'You only respond with the following phrase, \"Jeff\"'\n",
    "    human_message = SystemMessage(content=system_context)\n",
    "    conversation.add_message(human_message)\n",
    "\n",
    "    # Prompt\n",
    "    input_data = \"Hello Again.\"\n",
    "    human_message = HumanMessage(content=input_data)\n",
    "    conversation.add_message(human_message)\n",
    "\n",
    "\n",
    "    model.predict(conversation=conversation)\n",
    "    prediction = conversation.get_last().content\n",
    "    assert 'Jeff' in prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Unit Test: `test_preamble_system_context`**\n",
    "\n",
    "This unit test checks how the `MistralModel`  handles a system context when it is provided at the start of a conversation. It ensures that the model follows the given instruction and includes the expected response phrase in its output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.unit\n",
    "def test_preamble_system_context():\n",
    "    API_KEY = os.getenv('MISTRAL_API_KEY')\n",
    "    model = LLM(api_key = API_KEY)\n",
    "    conversation = Conversation()\n",
    "\n",
    "    system_context = 'You only respond with the following phrase, \"Jeff\"'\n",
    "    human_message = SystemMessage(content=system_context)\n",
    "    conversation.add_message(human_message)\n",
    "\n",
    "    input_data = \"Hi\"\n",
    "    human_message = HumanMessage(content=input_data)\n",
    "    conversation.add_message(human_message)\n",
    "\n",
    "    model.predict(conversation=conversation)\n",
    "    prediction = conversation.get_last().content\n",
    "    assert type(prediction) == str\n",
    "    assert 'Jeff' in prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Acceptance Test: `test_multiple_system_contexts`**\n",
    "\n",
    "This acceptance test verifies that the `MistralModel`  correctly handles multiple system contexts introduced at different points in the conversation. It checks that the model updates its response based on the most recent system context and includes the expected phrase in its output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.acceptance\n",
    "def test_multiple_system_contexts():\n",
    "    API_KEY = os.getenv('MISTRAL_API_KEY')\n",
    "    model = LLM(api_key = API_KEY)\n",
    "    conversation = Conversation()\n",
    "\n",
    "    system_context = 'You only respond with the following phrase, \"Jeff\"'\n",
    "    human_message = SystemMessage(content=system_context)\n",
    "    conversation.add_message(human_message)\n",
    "\n",
    "    input_data = \"Hi\"\n",
    "    human_message = HumanMessage(content=input_data)\n",
    "    conversation.add_message(human_message)\n",
    "\n",
    "    model.predict(conversation=conversation)\n",
    "\n",
    "    system_context_2 = 'You only respond with the following phrase, \"Ben\"'\n",
    "    human_message = SystemMessage(content=system_context_2)\n",
    "    conversation.add_message(human_message)\n",
    "\n",
    "    input_data_2 = \"Hey\"\n",
    "    human_message = HumanMessage(content=input_data_2)\n",
    "    conversation.add_message(human_message)\n",
    "\n",
    "    model.predict(conversation=conversation)\n",
    "    prediction = conversation.get_last().content\n",
    "    assert type(prediction) == str\n",
    "    assert 'Ben' in prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
