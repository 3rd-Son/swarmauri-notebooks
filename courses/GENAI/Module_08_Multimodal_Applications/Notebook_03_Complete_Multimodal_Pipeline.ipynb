{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Complete Multimodal Pipeline** \n",
    "# **Introduction**\n",
    "This notebook demonstrates how to create a complete pipeline combining text, image, and audio processing using swarmauri.\n",
    "By using the swarmauri library's integration with various AI models, we'll demonstrate how to create a robust system that can handle diverse types of content and data.\n",
    "\n",
    "The ability to  integrate multiple modalities opens up a wide range of possibilities, from automated content creation and localization to interactive storytelling and multimedia presentations. In this notebook, we'll explore practical use cases that illustrate the power of these multimodal techniques.\n",
    "\n",
    "You'll learn how to orchestrate a  pipeline that can generate images from textual descriptions, convert text to  audio narrations, and even process content in parallel for improved efficiency. By the end of this notebook, you'll have a solid understanding of how to build your own end-to-end multimodal solutions\n",
    "## **Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from swarmauri.llms.concrete.OpenAIImgGenModel import OpenAIImgGenModel\n",
    "from swarmauri.llms.concrete.OpenAIAudioTTS import OpenAIAudioTTS\n",
    "from swarmauri.llms.concrete.GroqAIAudio import GroqAIAudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load environment variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# Initialize all models\n",
    "img_model = OpenAIImgGenModel(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "tts_model = OpenAIAudioTTS(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "audio_model = GroqAIAudio(api_key=os.getenv(\"GROQ_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Basic Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_story(story_text):\n",
    "    \"\"\"Process a story through multiple modalities\"\"\"\n",
    "    \n",
    "    # Generate image from story\n",
    "    image_prompt = f\"Illustration for story: {story_text[:100]}\"\n",
    "    image_urls = img_model.generate_image(prompt=image_prompt)\n",
    "    \n",
    "    # Convert story to speech\n",
    "    audio_path = \"story_narration.mp3\"\n",
    "    audio_file = tts_model.predict(text=story_text, audio_path=audio_path)\n",
    "    \n",
    "    return {\n",
    "        \"image_url\": image_urls[0],\n",
    "        \"audio_path\": audio_file\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example usage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "story = \"\"\"\n",
    "A small robot discovered a garden filled with mechanical flowers.\n",
    "Each flower played a different musical note when touched.\n",
    "\"\"\"\n",
    "\n",
    "results = process_story(story)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image URL: https://oaidalleapiprodscus.blob.core.windows.net/private/org-apgARqqdlfy55Yko1fPIICVn/user-Xo2ejY1sCkk0iPxHhDLqVevG/img-XC6Jb9JPHpBKvDXtq8ltRheT.png?st=2024-11-05T11%3A38%3A02Z&se=2024-11-05T13%3A38%3A02Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-11-04T20%3A26%3A37Z&ske=2024-11-05T20%3A26%3A37Z&sks=b&skv=2024-08-04&sig=CqqE4HcY/X41aBqGgyV9K%2B2ah70YZqpJQTe/bIxYy94%3D\n",
      "\n",
      "Audio Name: story_narration.mp3\n"
     ]
    }
   ],
   "source": [
    "# Extract just the file name from audio_path\n",
    "audio_name = Path(results['audio_path']).name\n",
    "\n",
    "# Print output with keys\n",
    "print(f\"Image URL: {results['image_url']}\")\n",
    "print(f\"\\nAudio Name: {audio_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Parallel Processing Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def process_content_parallel(text_contents):\n",
    "    \"\"\"Process multiple content pieces in parallel\"\"\"\n",
    "    \n",
    "    async def process_single(text):\n",
    "        image_url = await img_model.agenerate_image(prompt=text)\n",
    "        audio_path = f\"content_{hash(text)}.mp3\"\n",
    "        audio_file = await tts_model.apredict(text=text, audio_path=audio_path)\n",
    "        return {\"text\": text, \"image\": image_url, \"audio\": audio_file}\n",
    "    \n",
    "    tasks = [process_single(text) for text in text_contents]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Example usage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "contents = [\n",
    "    \"A peaceful mountain lake at sunrise\",\n",
    "    \"A busy city street during rush hour\",\n",
    "    \"A quiet forest path in autumn\"\n",
    "]\n",
    "\n",
    "async_results = await process_content_parallel(contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Script: A peaceful mountain lake at sunrise\n",
      "Image URL: ['https://oaidalleapiprodscus.blob.core.windows.net/private/org-apgARqqdlfy55Yko1fPIICVn/user-Xo2ejY1sCkk0iPxHhDLqVevG/img-jBBnjEoDNz2QK21KWd8EcOdc.png?st=2024-11-05T12%3A01%3A09Z&se=2024-11-05T14%3A01%3A09Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-11-05T03%3A01%3A08Z&ske=2024-11-06T03%3A01%3A08Z&sks=b&skv=2024-08-04&sig=b1O59vJssSG/MW0ENGjAUHOFWfzJU3h7BdVs8yUqNeE%3D']\n",
      "Audio Name: content_3573223842926064870.mp3\n",
      "\n",
      "Script: A busy city street during rush hour\n",
      "Image URL: ['https://oaidalleapiprodscus.blob.core.windows.net/private/org-apgARqqdlfy55Yko1fPIICVn/user-Xo2ejY1sCkk0iPxHhDLqVevG/img-Yv0Ti5a6rnIbVp0vkuMAJlT0.png?st=2024-11-05T12%3A01%3A07Z&se=2024-11-05T14%3A01%3A07Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-11-04T20%3A15%3A15Z&ske=2024-11-05T20%3A15%3A15Z&sks=b&skv=2024-08-04&sig=hGD4qP5uNx/9oOj3%2BBGeI/%2BfvdQQLb7zzfkOVgn7FCQ%3D']\n",
      "Audio Name: content_339805538544973254.mp3\n",
      "\n",
      "Script: A quiet forest path in autumn\n",
      "Image URL: ['https://oaidalleapiprodscus.blob.core.windows.net/private/org-apgARqqdlfy55Yko1fPIICVn/user-Xo2ejY1sCkk0iPxHhDLqVevG/img-Lgj3UFh3padUu85FUJt9tnN0.png?st=2024-11-05T12%3A01%3A08Z&se=2024-11-05T14%3A01%3A08Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-11-04T19%3A34%3A52Z&ske=2024-11-05T19%3A34%3A52Z&sks=b&skv=2024-08-04&sig=LdqdB6WGt/bM4SYf6t8dRZvANMW%2BODz%2BdyKOctb%2Bf3w%3D']\n",
      "Audio Name: content_-3512611018140832382.mp3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for result in async_results:\n",
    "    # Extract just the file name from audio_path\n",
    "    audio_name = Path(result['audio']).name\n",
    "    # Print output with keys\n",
    "    print(f\"\\nScript: {result['text']}\")\n",
    "    print(f\"Image URL: {result['image']}\")\n",
    "    print(f\"Audio Name: {audio_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Conclusion**\n",
    "**This notebook has showcased the tremendous potential of a complete multimodal pipeline, leveraging the capabilities of the swarmauri library. You've learned how to:**\n",
    "\n",
    "Integration of multiple AI modalities\n",
    "\n",
    "Implement sequential and parallel processing pipelines to handle diverse content types.\n",
    "\n",
    "Explore practical use cases, such as automated course content creation and interactive storytelling.\n",
    "\n",
    "\n",
    "By mastering the techniques presented in this notebook, you'll be equipped to tackle a wide range of multimodal challenges, from enhancing user experiences to streamlining content creation workflows. \n",
    "\n",
    "We encourage you to continue exploring the boundaries of what's possible with these powerful AI-driven tools, and to innovate new and exciting multimodal applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swarmauri-0.5.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
