{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Real World Use Cases with Swarmauri**\n",
    "\n",
    "## **Introduction**\n",
    "This notebook presents practical real-world applications using swarmauri's multimodal capabilities.\n",
    "In this final notebook, we shift our focus to the practical application of multimodal AI techniques in real-world scenarios. By exploring various use cases, we'll demonstrate how the  integration of text, image, and audio can lead to innovative solutions that enhance user experiences and improve content creation workflows.\n",
    "\n",
    "Throughout this notebook, we'll delve into three distinct use cases that showcase the versatility of the swarmauri library's multimodal capabilities. From automated course content generation to multilingual content localization and interactive storytelling, you'll learn how to apply these powerful tools to address real-world challenges.\n",
    "\n",
    "Each use case will be accompanied by well-designed, production-ready code examples, providing you with a solid foundation to build upon. By understanding the motivations, requirements, and implementation details of these use cases, you'll be better equipped to identify and address similar challenges in your own projects.\n",
    "\n",
    "## **Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from swarmauri.llms.concrete.OpenAIImgGenModel import OpenAIImgGenModel\n",
    "from swarmauri.llms.concrete.OpenAIAudioTTS import OpenAIAudioTTS\n",
    "from swarmauri.llms.concrete.GroqAIAudio import GroqAIAudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load environment variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Use Case 1: Automated Course Content Creation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CourseContentGenerator:\n",
    "    def __init__(self):\n",
    "        self.img_model = OpenAIImgGenModel(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "        self.tts_model = OpenAIAudioTTS(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "    \n",
    "    def create_lesson(self, lesson_text, title):\n",
    "        # Generate illustration\n",
    "        image_url = self.img_model.generate_image(\n",
    "            prompt=f\"Educational illustration for: {title}\"\n",
    "        )[0]\n",
    "        \n",
    "        # Create audio narration\n",
    "        audio_path = f\"lesson_{title.lower().replace(' ', '_')}.mp3\"\n",
    "        audio_file = self.tts_model.predict(\n",
    "            text=lesson_text,\n",
    "            audio_path=audio_path\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"title\": title,\n",
    "            \"text\": lesson_text,\n",
    "            \"illustration\": image_url,\n",
    "            \"narration\": audio_file\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "generator = CourseContentGenerator()\n",
    "lesson = generator.create_lesson(\n",
    "    \"Photosynthesis is the process by which plants convert sunlight into energy.\",\n",
    "    \"Introduction to Photosynthesis\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print output course content output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract just the file name from audio_path\n",
    "audio_name = Path(lesson['narration']).name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Course Title: Introduction to Photosynthesis\n",
      "\n",
      "Script: Photosynthesis is the process by which plants convert sunlight into energy.\n",
      "Image URL: https://oaidalleapiprodscus.blob.core.windows.net/private/org-apgARqqdlfy55Yko1fPIICVn/user-Xo2ejY1sCkk0iPxHhDLqVevG/img-FBMwXBCahj73JpRtL1h5KF0C.png?st=2024-11-05T12%3A29%3A30Z&se=2024-11-05T14%3A29%3A30Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-11-04T19%3A10%3A43Z&ske=2024-11-05T19%3A10%3A43Z&sks=b&skv=2024-08-04&sig=IC6SwlqawWZ/K1h6YkNB227fQUFTcCCSYc5xTL18tpA%3D\n",
      "Audio Name: lesson_introduction_to_photosynthesis.mp3\n"
     ]
    }
   ],
   "source": [
    "# Print output with keys\n",
    "print(f\"\\nCourse Title: {lesson['title']}\")\n",
    "print(f\"\\nScript: {lesson['text']}\")\n",
    "print(f\"Image URL: {lesson['illustration']}\")\n",
    "print(f\"Audio Name: {audio_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Use Case 2: Multilingual Content Creation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use Case 2: Multilingual Content Creation\n",
    "class ContentLocalizer:\n",
    "    def __init__(self):\n",
    "        self.tts_model = OpenAIAudioTTS(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "        self.audio_model = GroqAIAudio(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
    "    \n",
    "    def process_content(self, audio_path, output_path):\n",
    "        # Transcribe audio\n",
    "        transcript = self.audio_model.predict(\n",
    "            audio_path=audio_path,\n",
    "            task=\"translation\"\n",
    "        )\n",
    "        \n",
    "        # Generate translated audio\n",
    "        audio_file = self.tts_model.predict(\n",
    "            text=transcript,\n",
    "            audio_path=output_path\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"transcript\": transcript,\n",
    "            \"audio_file\": audio_file\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example usage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "localizer = ContentLocalizer()\n",
    "result = localizer.process_content(\n",
    "    \"French.mp3\",\n",
    "    \"english_output.mp3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print output course content output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract just the file name from audio_path\n",
    "audio_name = Path(result['audio_file']).name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Script:  Hello. Hello. May I? Yes, of course. Oh, my God. Sorry. It's all right. I'm just a little bit tired. I'm going to go and get some rest. I'm going to go and get some rest. I'm going to go and get some rest. I'm going to go and get some rest. I'm going to go and get some rest. I'm going to go and get some rest. I'm going to go and get some rest. I'm going to go and get some rest. I'm going to go and get some rest. I'm going to go and get some rest. I'm going to go and get some rest. I'm going to go and get some rest. I'm going to go and get some rest. I'm going to go and get some rest. Sorry. It's all right. What's your name? Cécile. And you? My name is François. I'm delighted to meet you. You come from here? Yes, I live here. And you? I come from La Rochelle. What do you do in life? I'm a gallerist. I have a small gallery in the 10th. I'm a gallerist. I have a small gallery in the 10th. I'm a gallerist. I have a small gallery in the 10th. I'm a gallerist. I'm a gallerist. I'm a gallerist. I'm a gallerist. I'm a gallerist. I'm a gallerist. I'm a gallerist. I'm a gallerist. I'm a gallerist. I have a small gallery in the 10th. And you? I'm an actor. I play in a small theatre. Ah, interesting. And how old are you? I'm 32. And you? Guess 30 maybe No I 31 years old You know I looking for a small apartment Do you have any advice Can you help me Yes, I can help you. But it's already late, I still have a meeting with a client. Do you have time tomorrow around 3pm to go for a coffee? Yes, of course. Can you give me your phone number? So, my mobile number is 06 23 04 87 58. Ok. And yours? Mine is 06 89 54 42 61. I'm sorry. I'll call you tomorrow for our meeting. All right. Goodbye. Goodbye. See you tomorrow. See you tomorrow.\n",
      "Audio Name: english_output.mp3\n"
     ]
    }
   ],
   "source": [
    "# Print output with keys\n",
    "print(f\"\\nScript: {result['transcript']}\")\n",
    "print(f\"Audio Name: {audio_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Use Case 3: Interactive Story Creation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use Case 3: Interactive Story Creation\n",
    "class StoryCreator:\n",
    "    def __init__(self):\n",
    "        self.img_model = OpenAIImgGenModel(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "        self.tts_model = OpenAIAudioTTS(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "    \n",
    "    async def create_story_scene(self, scene_text, scene_number):\n",
    "        # Generate scene illustration\n",
    "        image_url = await self.img_model.agenerate_image(\n",
    "            prompt=f\"Story scene: {scene_text}\"\n",
    "        )\n",
    "        \n",
    "        # Create scene narration\n",
    "        audio_path = f\"scene_{scene_number}.mp3\"\n",
    "        audio_file = await self.tts_model.apredict(\n",
    "            text=scene_text,\n",
    "            audio_path=audio_path\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"scene_number\": scene_number,\n",
    "            \"text\": scene_text,\n",
    "            \"illustration\": image_url[0],\n",
    "            \"narration\": audio_file\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example usage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "creator = StoryCreator()\n",
    "scene = await creator.create_story_scene(\n",
    "    \"The magical tree glowed with a soft blue light\", 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print Interactive story Creation output** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract just the file name from audio_path\n",
    "audio_name = Path(scene['narration']).name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "scene_number: 1\n",
      "\n",
      "Script: The magical tree glowed with a soft blue light\n",
      "Image URL: https://oaidalleapiprodscus.blob.core.windows.net/private/org-apgARqqdlfy55Yko1fPIICVn/user-Xo2ejY1sCkk0iPxHhDLqVevG/img-oSG3VMcXnwp5lXlHYZp5BmOt.png?st=2024-11-05T13%3A00%3A51Z&se=2024-11-05T15%3A00%3A51Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-11-04T19%3A12%3A43Z&ske=2024-11-05T19%3A12%3A43Z&sks=b&skv=2024-08-04&sig=uaLah69GxCNjwlcBD5urmXjsBnJNLNstfWWPVgccamo%3D\n",
      "Audio Name: scene_1.mp3\n"
     ]
    }
   ],
   "source": [
    "# Print output with keys\n",
    "print(f\"\\nscene_number: {scene['scene_number']}\")\n",
    "print(f\"\\nScript: {scene['text']}\")\n",
    "print(f\"Image URL: {scene['illustration']}\")\n",
    "print(f\"Audio Name: {audio_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Conclusion**\n",
    "**This notebook has explored a diverse range of real-world use cases that highlight the transformative potential of multimodal AI technologies**\n",
    "\n",
    "**You've learned how to:**\n",
    "- Automate the creation of educational content, including text, images, and audio narrations, \n",
    "to streamline the content generation process.\n",
    "- Multilingual content processing\n",
    "- Develop interactive storytelling experiences that  combine text, images, and \n",
    "audio to create engaging and immersive narratives.\n",
    "\n",
    "\n",
    "These use cases represent just a fraction of the countless possibilities that emerge when we harness the power of integrated text, image, and audio processing. \n",
    "As you venture forth, we encourage you to continue exploring the potential of multimodal AI, identifying new challenges and innovative solutions that can transform industries and enrich the lives of users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swarmauri-0.5.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
