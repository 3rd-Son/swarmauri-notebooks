{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Notebook 04: Audio Parameters**\n",
    "# **Introduction:** \n",
    "\n",
    "In this notebook, we'll explore how various audio parameters affect the output of text-to-speech synthesis, leveraging the OpenAIAudioTTS class from the Swarmauri framework. By modifying parameters like model type, voice, and concurrency in batch processing, we gain fine-grained control over the generated audio output. Understanding these parameters will allow for more tailored and efficient TTS applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import of dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "from swarmauri.llms.concrete.OpenAIAudioTTS import OpenAIAudioTTS\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load environment variables and setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialize TTS model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tts = OpenAIAudioTTS(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Display model capabilities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI TTS Configuration:\n",
      "Available Models: ['tts-1', 'tts-1-hd']\n",
      "Available Voices: ['alloy', 'echo', 'fable', 'onyx', 'nova', 'shimmer']\n",
      "Default Model: tts-1\n",
      "Default Voice: alloy\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"OpenAI TTS Configuration:\")\n",
    "print(f\"Available Models: {tts.allowed_models}\")\n",
    "print(f\"Available Voices: {tts.allowed_voices}\")\n",
    "print(f\"Default Model: {tts.name}\")\n",
    "print(f\"Default Voice: {tts.voice}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup output directory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_dir = Path(\"output\")\n",
    "output_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.** **Basic Text-to-Speech Generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"Welcome to the text-to-speech demonstration using OpenAI's TTS service.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate speech with default settings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating basic TTS output...\n",
      "\n",
      "Demonstration complete! Check the output directory for generated audio files.\n"
     ]
    }
   ],
   "source": [
    "output_path = output_dir / \"basic_output.mp3\"\n",
    "print(\"\\nGenerating basic TTS output...\")\n",
    "audio_file = tts.predict(\n",
    "    text=sample_text,\n",
    "    audio_path=str(output_path)\n",
    ")\n",
    "\n",
    "print(\"\\nDemonstration complete! Check the output directory for generated audio files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Try Different Voices**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\nGenerating samples with different voices...\")\n",
    "for voice in tts.allowed_voices:\n",
    "    tts.voice = voice\n",
    "    voice_path = output_dir / f\"voice_{voice}.mp3\"\n",
    "    audio_file = tts.predict(\n",
    "        text=sample_text,\n",
    "        audio_path=str(voice_path)\n",
    "    )\n",
    "    print(f\"This is the {voice} voice speaking.\")\n",
    "    print(f\"\\nDemonstration complete! Check the output directory for generated {voice} audio files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Streaming Audio Generation**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDemonstrating streaming audio generation...\")\n",
    "stream_text = \"This is a streaming audio demonstration.\"\n",
    "print(\"Collecting audio chunks...\")\n",
    "chunk_count = 0\n",
    "for chunk in tts.stream(text=stream_text):\n",
    "    chunk_count += 1\n",
    "print(f\"Received {chunk_count} audio chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Batch Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\nDemonstrating batch processing...\")\n",
    "batch_texts = {\n",
    "    \"Hello world\": str(output_dir / \"batch_1.mp3\"),\n",
    "    \"This is a test\": str(output_dir / \"batch_2.mp3\"),\n",
    "    \"Batch processing demo\": str(output_dir / \"batch_3.mp3\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_results = tts.batch(text_path_dict=batch_texts)\n",
    "print(\"Batch processing results:\")\n",
    "for result in batch_results:\n",
    "    print(f\"Generated: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Async Operations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Async prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDemonstrating async operations...\")\n",
    "async_output = output_dir / \"async_output.mp3\"\n",
    "result = await tts.apredict(\n",
    "    text=\"This is an async TTS test\",\n",
    "    audio_path=str(async_output)\n",
    ")\n",
    "print(\"\\nDemonstration complete! Check the output directory for generated audio files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Async batch processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async_batch = {\n",
    "        \"First async message\": str(output_dir / \"async_1.mp3\"),\n",
    "        \"Second async message\": str(output_dir / \"async_2.mp3\")\n",
    "    }\n",
    "results = await tts.abatch(text_path_dict=async_batch, max_concurrent=2)\n",
    "print(\"Async batch results:\")\n",
    "for result in results:\n",
    "    print(f\"Generated: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. High-Definition Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trying HD model...\n",
      "\n",
      "Demonstration complete! Check the output directory for generated audio files.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"\\nTrying HD model...\")\n",
    "tts.name = \"tts-1-hd\"\n",
    "hd_output = output_dir / \"hd_output.mp3\"\n",
    "hd_result = tts.predict(\n",
    "    text=\"This is high-definition text-to-speech audio.\",\n",
    "    audio_path=str(hd_output)\n",
    ")\n",
    "\n",
    "print(\"\\nDemonstration complete! Check the output directory for generated audio files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Conclusion:**\n",
    "\n",
    "In this notebook, we explored different audio parameters, including model selection, voice variation, streaming, and batch processing with concurrency control. \n",
    "These parameter adjustments provide flexibility in TTS applications, from real-time streaming to high-volume processing. Understanding and effectively tuning these parameters will enable efficient and adaptable audio generation solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swarmauri-0.5.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
