{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Notebook_01_Intro_to_Audio_Generation**\n",
    "## **Introduction**\n",
    "\n",
    "In recent years, audio generation has emerged as a transformative field, bridging the gap between machine understanding and human interaction. Applications in speech synthesis, audio translation, and transcription are reshaping industries, from customer support and accessibility services to entertainment and education. This notebook introduces the foundational aspects of audio generation, emphasizing Swarmauri’s SDK capabilities, particularly through the GroqAIAudio module. Swarmauri SDK is designed to streamline the integration of complex audio functionalities with minimal setup, enabling developers to create, modify, and manage audio tasks efficiently.\n",
    "\n",
    "We’ll explore core concepts of audio data handling and transformation to provide a practical foundation for using GroqAIAudio. This SDK offers multiple pre-trained models and supports an array of tasks, including audio transcription, translation, and speech synthesis, which are pivotal for interactive and multilingual applications. By the end of this notebook, users will be well-versed in Swarmauri SDK's structure and how it can support scalable and efficient audio processing workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from swarmauri.llms.concrete.GroqAIAudio import GroqAIAudio\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set up environment**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialize the GroqAIAudio model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = GroqAIAudio(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check model information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Resource: LLM\n",
      "Model Type: GroqAIAudio\n",
      "Default Model Name: distil-whisper-large-v3-en\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Model Resource: {llm.resource}\")\n",
    "print(f\"Model Type: {llm.type}\")\n",
    "print(f\"Default Model Name: {llm.name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get list of allowed models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available Models:\n",
      "- distil-whisper-large-v3-en\n",
      "- whisper-large-v3\n"
     ]
    }
   ],
   "source": [
    "available_models = llm.allowed_models\n",
    "print(\"\\nAvailable Models:\")\n",
    "for model in available_models:\n",
    "    print(f\"- {model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic audio file setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = Path.cwd()\n",
    "audio_path = os.path.join(root_dir, \"Recording.m4a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simple transcription example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transcribing audio file...\n",
      "Transcription result:  And we're going to be able to be ha'amu'all.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTranscribing audio file...\")\n",
    "transcription = llm.predict(audio_path=audio_path)\n",
    "print(f\"Transcription result: {transcription}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model serialization example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model serialization:\n",
      "Model JSON: {\"name\":\"distil-whisper-large-v3-en\",\"id\":\"9c5a94ca-08ca-450e-900f-444f0b09d763\",\"members\":[],\"owner\":null,\"host\":null,\"resource\":\"LLM\",\"version\":\"0.1.0\",\"type\":\"GroqAIAudio\",\"allowed_models\":[\"distil-whisper-large-v3-en\",\"whisper-large-v3\"],\"api_key\":\"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\"}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model_json = llm.model_dump_json()\n",
    "print(\"\\nModel serialization:\")\n",
    "print(f\"Model JSON: {model_json}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validate model serialization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validated Model ID: 9c5a94ca-08ca-450e-900f-444f0b09d763\n"
     ]
    }
   ],
   "source": [
    "\n",
    "validated_model = GroqAIAudio.model_validate_json(model_json)\n",
    "print(f\"Validated Model ID: {validated_model.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Conclusion**\n",
    "\n",
    "This introduction to audio generation through the Swarmauri SDK has highlighted its powerful, model-based framework for handling varied audio tasks. Swarmauri’s GroqAIAudio module simplifies traditionally complex audio operations, enabling quick experimentation and development. With this foundation, you can now delve into more specific functionalities, such as transcription, translation, and parameter tuning, which will be explored in subsequent notebooks. \n",
    "Leveraging Swarmauri’s tools can ultimately enhance user engagement, promote accessibility, and open new possibilities in human-computer interaction through audio.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from swarmauri.utils.print_notebook_metadata  import print_notebook_metadata\n",
    "\n",
    "print_notebook_metadata(author_name = \"Dominion John \" , github_username = \"DOMINION-JOHN1\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swarmauri-0.5.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
