{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Notebook_02_Working_with_GroqAudio**\n",
    "## **Introduction**\n",
    "This notebook delves into using Swarmauri’s GroqAIAudio module to perform essential audio tasks, focusing on transcription and translation functionalities. The GroqAIAudio class, part of the Swarmauri SDK, provides an interface for connecting with high-performance language models that process and analyze audio files. Using the LLM module from Swarmauri’s SDK allows us to perform tasks like audio transcription, which converts spoken language in audio files to text, and translation, which translates audio into another language—a key functionality for cross-lingual applications. \n",
    "These tasks can streamline workflows for automated content generation, meeting accessibility standards, and enhancing customer service through seamless multilingual support.\n",
    "\n",
    "**In this notebook, we will explore how to:**\n",
    "\n",
    "Initialize GroqAIAudio with API configurations for performing audio tasks.\n",
    "\n",
    "Use the module’s methods to transcribe and translate audio files.\n",
    "\n",
    "Understand error handling and model selection for various use cases, ensuring optimized and reliable audio processing.\n",
    "\n",
    "This section will offer a hands-on understanding of how Swarmauri SDK’s modular approach simplifies real-time audio management, making it possible to integrate robust audio capabilities in production-grade applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import of dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from swarmauri.llms.concrete.GroqAIAudio import GroqAIAudio\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialize with API key**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "llm = GroqAIAudio(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set up file paths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up file paths\n",
    "root_dir = Path.cwd()\n",
    "english_audio = os.path.join(root_dir, \"Recording.m4a\")\n",
    "french_audio = os.path.join(root_dir, \"French.mp3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic English Transcription**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "English Audio Transcription:\n",
      " And we're going to be able to be ha'amu'all.\n"
     ]
    }
   ],
   "source": [
    "llm.name = \"distil-whisper-large-v3-en\"  # Set default model\n",
    "english_transcription = llm.predict(audio_path=english_audio)\n",
    "print(\"\\nEnglish Audio Transcription:\")\n",
    "print(english_transcription)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Using Different Models**\n",
    "\n",
    "**Try transcription with different allowed models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trying model: distil-whisper-large-v3-en\n",
      "Transcription:  And we're going to be able to be ha'amu'all.\n",
      "\n",
      "Trying model: whisper-large-v3\n",
      "Transcription:  Hello.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for model_name in llm.allowed_models:\n",
    "    print(f\"\\nTrying model: {model_name}\")\n",
    "    llm.name = model_name\n",
    "    try:\n",
    "        result = llm.predict(audio_path=english_audio)\n",
    "        print(f\"Transcription: {result}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error with {model_name}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Translation Task**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Bonjour. Bonjour. Je peux ? Oui, bien sûr. Mince ! Pardon. C'est pas grave. Tu t'appelles comment ? Cécile. Et toi ? Je m'appelle François. Je suis ravi de te rencontrer. Tu viens d'ici ? Oui, j'habite ici. Et toi ? Je viens de La Rochère. Tu fais quoi dans la vie ? Je suis galeriste. J'ai une petite galerie dans le dixième. Et toi ? Je suis acteur. Je joue dans un petit théâtre. Ah ! Intéressant ! et tu as quel j 32 ans et toi devine 30 peut non j 31 ans tu sais je cherche un petit appartement tu as des conseils tu peux peut m'aider oui je peux t'aider mais il est déjà tard j'ai encore un rendez vous avec un client tu as le temps demain vers 15 heures pour aller boire un café oui bien sûr tu me donnes ton numéro de téléphone Alors, mon numéro de portable, c'est le 06 23 04 87 58. Ok. Et le tien ? Le mien, c'est le 06 89 54 42 61. Ok, je t'appelle demain pour notre rendez-vous alors D'accord Au revoir Au revoir A demain alors A demain Merci.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict(audio_path=french_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Translating French Audio:\n",
      "Translation result:  Hello. Hello. May I? Yes, of course. Oh, my God. Sorry. It's all right. I'm just a little bit tired. I'm going to go and get some rest. I'm going to go and get some rest. I'm going to go and get some rest. I'm going to go and get some rest. I'm going to go and get some rest. I'm going to go and get some rest. I'm going to go and get some rest. I'm going to go and get some rest. I'm going to go and get some rest. I'm going to go and get some rest. I'm going to go and get some rest. I'm going to go and get some rest. I'm going to go and get some rest. I'm going to go and get some rest. Sorry. It's all right. What's your name? Cécile. And you? My name is François. I'm delighted to meet you. You come from here? Yes, I live here. And you? I come from La Rochelle. What do you do in life? I'm a gallerist. I have a small gallery in the 10th. I'm a gallerist. I have a small gallery in the 10th. I'm a gallerist. I have a small gallery in the 10th. I'm a gallerist. I'm a gallerist. I'm a gallerist. I'm a gallerist. I'm a gallerist. I'm a gallerist. I'm a gallerist. I'm a gallerist. I'm a gallerist. I have a small gallery in the 10th. And you? I'm an actor. I play in a small theatre. Ah, interesting. And how old are you? I'm 32. And you? Guess 30 maybe No I 31 years old You know I looking for a small apartment Do you have any advice Can you help me Yes, I can help you. But it's already late, I still have a meeting with a client. Do you have time tomorrow around 3pm to go for a coffee? Yes, of course. Can you give me your phone number? So, my mobile number is 06 23 04 87 58. Ok. And yours? Mine is 06 89 54 42 61. I'm sorry. I'll call you tomorrow for our meeting. All right. Goodbye. Goodbye. See you tomorrow. See you tomorrow.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nTranslating French Audio:\")\n",
    "llm.name = \"whisper-large-v3\"  # Set appropriate model for translation\n",
    "translation = llm.predict(\n",
    "    audio_path=french_audio,\n",
    "    task=\"translation\"\n",
    ")\n",
    "print(f\"Translation result: {translation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Details:\n",
      "Current Model: whisper-large-v3\n",
      "Model Type: GroqAIAudio\n",
      "Resource: LLM\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nModel Details:\")\n",
    "print(f\"Current Model: {llm.name}\")\n",
    "print(f\"Model Type: {llm.type}\")\n",
    "print(f\"Resource: {llm.resource}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Conclusion**\n",
    "The GroqAIAudio module, as demonstrated, enables efficient and high-accuracy transcription and translation within a few lines of code. Swarmauri’s SDK not only automates these processes but also provides a robust environment for managing complex audio requirements in a scalable way. \n",
    "\n",
    "By leveraging GroqAIAudio, You  can simplify the implementation of multilingual features and streamline audio-based workflows across applications. This notebook reinforces the potential of Swarmauri’s toolkit for real-time audio needs, making it a powerful resource for professionals looking to innovate in audio technology and beyond."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from swarmauri.utils.print_notebook_metadata  import print_notebook_metadata\n",
    "\n",
    "print_notebook_metadata(author_name = \"Dominion John \" , github_username = \"DOMINION-JOHN1\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swarmauri-0.5.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
