{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Understanding Large Language Models (LLMs)**\n",
    "## **Introduction**\n",
    "\n",
    "Large Language Models (LLMs) represent a significant leap in the field of Natural Language Processing (NLP) and Artificial Intelligence. These models, designed to understand and generate human-like text, have transformed how machines process and respond to human language, bridging the gap between raw data and coherent, context-aware communication. Developed by training on vast corpora of textual data, LLMs learn complex language structures, idiomatic expressions, and even the subtleties of cultural references. This enables them to engage in tasks ranging from simple sentence completion to sophisticated reasoning and problem-solving.\n",
    "\n",
    "LLMs operate on the principles of deep learning and transformer architectures. Introduced by the Vaswani et al. paper, \"Attention is All You Need,\" transformer architectures leverage self-attention mechanisms, which allow models to focus on different parts of an input sentence for improved context comprehension. This capability allows LLMs to handle dependencies and contextual meanings across long passages, something previous models like RNNs and LSTMs struggled with.\n",
    "\n",
    "This first notebook introduces the foundational concepts of Large Language Models (LLMs), covering their architecture, key functionalities, and typical use cases. LLMs, trained on massive datasets, exhibit advanced capabilities that allow them to perform tasks across domains with minimal task-specific training. By understanding the core structure and capabilities of LLMs, users can better appreciate their versatility and gain insight into how these models drive diverse applications, from generating complex narratives to enabling human-like conversational responses.\n",
    "\n",
    "**This notebook will:**\n",
    "\n",
    "\n",
    "Demonstrate basic LLM capabilities using the GeminiPro model.\n",
    "\n",
    "Introduce practical examples for common LLM tasks, such as text generation and summarization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import of dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from swarmauri.llms.concrete.MistralModel import MistralModel as LLM\n",
    "from swarmauri.conversations.concrete.Conversation import Conversation\n",
    "from swarmauri.messages.concrete.HumanMessage import HumanMessage\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load API Key from environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Fetch the API key from environment variables\n",
    "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialize Mistral LLM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistral_model = LLM(api_key=MISTRAL_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a conversation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = Conversation()\n",
    "conversation.add_message(HumanMessage(content=\"Explain quantum computing in simple terms\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predict response**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum computing is a new kind of computing technology that uses the principles of quantum mechanics to process information. In contrast to classical computers, which use bits to represent and process information, quantum computers use quantum bits, or qubits.\n",
      "\n",
      "Qubits are unique because they can exist in multiple states at once, a property known as superposition. This means that a single qubit can represent a 0 and a 1 simultaneously, allowing quantum computers to perform many calculations at once.\n",
      "\n",
      "Another important property of qubits is entanglement, which allows them to become linked in such a way that the state of one qubit can affect the state of another qubit, even if they are separated by large distances.\n",
      "\n",
      "These properties of superposition and entanglement allow quantum computers to perform certain calculations much faster than classical computers. However, quantum computing is still a relatively new and complex field, and there are many technical challenges that must be overcome before quantum computers can be widely used.\n",
      "\n",
      "In simple terms, quantum computing is a new and powerful technology that uses the principles of quantum mechanics to perform calculations much faster than classical computers. It is a rapidly evolving field with many potential applications in fields such as cryptography, optimization, and materials science.\n"
     ]
    }
   ],
   "source": [
    "response = mistral_model.predict(conversation=conversation)\n",
    "print(response.get_last().content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use Streaming instead of predict (Token-by-Token Generation) :** Be observant to note the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = Conversation()\n",
    "conversation.add_message(HumanMessage(content=\"Write a short story about a swarmauri\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the lush and vibrant world of Velnara, there existed a unique and mysterious creature known as the swarmauri. The swarmauri was a small, winged being with iridescent feathers that shimmered in the light. They had the ability to manipulate sound waves and create mesmerizing melodies that could soothe even the most troubled of souls.\n",
      "\n",
      "One such swarmauri was named Lyri. She lived in a secluded treehouse in the heart of the Whispering Woods, where the trees were so dense that the sun's rays barely penetrated the canopy. Lyri spent her days perfecting her craft, composing intricate symphonies and experimenting with new sounds.\n",
      "\n",
      "One fateful day, while exploring the depths of the forest, Lyri stumbled upon a lost and weary traveler. The human, named Kael, had been separated from his caravan during a violent storm and had been wandering the woods for days. He was exhausted, hungry, and on the brink of despair when he heard the enchanting melody that Lyri was playing.\n",
      "\n",
      "Drawn to the music, Kael followed the sound"
     ]
    }
   ],
   "source": [
    "# Stream tokens from the model\n",
    "for token in mistral_model.stream(conversation=conversation):\n",
    "    print(token, end='', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Batch Processing Multiple Conversations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations = []\n",
    "\n",
    "# Populate the list with Conversation instances\n",
    "for prompt in [\"Hello\", \"Tell me a joke\", \"What is machine learning?\"]:\n",
    "    conv = Conversation()\n",
    "    conv.add_message(HumanMessage(content=prompt))\n",
    "    conversations.append(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Conversation(name=None, id='8879d125-dfc0-498f-89cd-0305f4f07086', members=[], owner=None, host=None, resource='Conversation', version='0.1.0', type='Conversation'), Conversation(name=None, id='b1d61258-345d-4cb0-9fde-bb6f4fc68b6d', members=[], owner=None, host=None, resource='Conversation', version='0.1.0', type='Conversation'), Conversation(name=None, id='2585b22b-fcfa-4b35-9a83-3a1d3efc77ff', members=[], owner=None, host=None, resource='Conversation', version='0.1.0', type='Conversation')]\n"
     ]
    }
   ],
   "source": [
    "print(conversations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I help you today? If you have any questions about a specific topic or just want to chat, feel free to ask. I'm here to provide information and engage in conversation on a wide range of subjects.\n",
      "Sure, here's a classic one for you:\n",
      "\n",
      "Why was the math book sad?\n",
      "\n",
      "Because it had too many problems.\n",
      "\n",
      "I hope that made you smile! Would you like to ask me anything else?\n",
      "Machine learning is a subfield of artificial intelligence (AI) that focuses on the development of algorithms and statistical models that enable computers to perform tasks without explicit programming. Instead of being explicitly programmed to perform a specific task, a machine learning model learns patterns and makes predictions or decisions based on data.\n",
      "\n",
      "Machine learning models can be trained on labeled data, where the desired output or \"label\" is provided for each input example, or on unlabeled data, where the model must learn patterns and relationships in the data without explicit guidance. Once trained, a machine learning model can make predictions or decisions on new, unseen data.\n",
      "\n",
      "Machine learning has a wide range of applications, including image and speech recognition, natural language processing, fraud detection, recommendation systems, and self-driving cars, among others. The field of machine learning is constantly evolving, with new algorithms and techniques being developed to improve the accuracy and efficiency of machine learning models.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11828\\1734914597.py:2: RuntimeWarning: coroutine 'MistralModel.abatch' was never awaited\n",
      "  batch_results = mistral_model.batch(conversations=conversations)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "# print batch reponse\n",
    "batch_results = mistral_model.batch(conversations=conversations)\n",
    "for result in batch_results:\n",
    "    print(result.get_last().content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a short story about a swarmauri\n",
      "In the lush and vibrant world of Velnara, there existed a unique and mysterious creature known as the swarmauri. The swarmauri was a small, winged being with iridescent feathers that shimmered in the light. They had the ability to manipulate sound waves and create mesmerizing melodies that could soothe even the most troubled of souls.\n",
      "\n",
      "One such swarmauri was named Lyri. She lived in a secluded treehouse in the heart of the Whispering Woods, where the trees were so dense that the sun's rays barely penetrated the canopy. Lyri spent her days perfecting her craft, composing intricate symphonies and experimenting with new sounds.\n",
      "\n",
      "One fateful day, while exploring the depths of the forest, Lyri stumbled upon a lost and weary traveler. The human, named Kael, had been separated from his caravan during a violent storm and had been wandering the woods for days. He was exhausted, hungry, and on the brink of despair when he heard the enchanting melody that Lyri was playing.\n",
      "\n",
      "Drawn to the music, Kael followed the sound\n"
     ]
    }
   ],
   "source": [
    "for message in conversation.history:\n",
    "    print(message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Conclusion**\n",
    "\n",
    "LLMs represent a significant breakthrough in artificial intelligence, enabling machines to understand, generate, and interact with human language in sophisticated ways. \n",
    "Mastering their basic usage, You can unlock powerful natural language processing capabilities.\n",
    "By completing this notebook, You gain a robust understanding of the fundamentals of LLMs and their vast potential in various applications.\n",
    "\n",
    " The insights and hands-on examples provided lay a solid foundation for further exploration into specific models, including Swarmauri’s GeminiPro and Mistral. With a clear grasp of how these models are structured , You are now well-prepared to make informed decisions about model use and integration in their projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **NOTEBOOK METADATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Dominion John \n",
      "GitHub Username: DOMINION-JOHN1\n",
      "Last Modified: 2024-10-31 13:20:06.457904\n",
      "Platform: Windows 11\n",
      "Python Version: 3.12.7 (tags/v3.12.7:0b05ead, Oct  1 2024, 03:06:41) [MSC v.1941 64 bit (AMD64)]\n",
      "Swarmauri Version: Swarmauri Version: 0.5.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import platform\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# Display author information\n",
    "author_name = \"Dominion John \" \n",
    "github_username = \"DOMINION-JOHN1\"  \n",
    "\n",
    "print(f\"Author: {author_name}\")\n",
    "print(f\"GitHub Username: {github_username}\")\n",
    "\n",
    "# Last modified datetime (file's metadata)\n",
    "notebook_file = \"Notebook_01_Understanding_LLMs.ipynb\"\n",
    "try:\n",
    "    last_modified_time = os.path.getmtime(notebook_file)\n",
    "    last_modified_datetime = datetime.fromtimestamp(last_modified_time)\n",
    "    print(f\"Last Modified: {last_modified_datetime}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not retrieve last modified datetime: {e}\")\n",
    "\n",
    "# Display platform, Python version, and Swarmauri version\n",
    "print(f\"Platform: {platform.system()} {platform.release()}\")\n",
    "print(f\"Python Version: {sys.version}\")\n",
    "\n",
    "import swarmauri\n",
    "\n",
    "try:\n",
    "    version = swarmauri.__version__\n",
    "except AttributeError:\n",
    "    version = f\"Swarmauri Version: 0.5.1\"\n",
    "\n",
    "print(f\"Swarmauri Version: {version}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swarmauri-0.5.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
