{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **System Context Management**\n",
    "# **Introduction**\n",
    "This notebook explores managing system context with real LLM integration using Groq. We'll see how different contexts affect LLM responses and how to manage context effectively. We'll explore how to set, update, and maintain system context throughout a conversation.\n",
    "\n",
    "## **Basic System Context Setup**\n",
    "\n",
    "Let's start with basic system context management:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from swarmauri.messages.concrete import SystemMessage, HumanMessage, AgentMessage\n",
    "from swarmauri.conversations.concrete.MaxSystemContextConversation import MaxSystemContextConversation\n",
    "import os\n",
    "from swarmauri.llms.concrete.GroqModel import GroqModel\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialize the model with API key**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "llm = GroqModel(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a conversation with initial system context**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial context: You are a Python programming expert\n"
     ]
    }
   ],
   "source": [
    "conversation = MaxSystemContextConversation(\n",
    "    system_context=SystemMessage(content=\"You are a Python programming expert\"),\n",
    "    max_size=4\n",
    ")\n",
    "\n",
    "# Print initial context\n",
    "print(f\"Initial context: {conversation.system_context.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Multiple Context Switching with LLM**\n",
    "**Example of handling different contexts:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create conversations with different contexts:**  Start with programming context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Programming Response: **1. Creating Lists:**\n",
      "\n",
      "```python\n",
      "# Basic list creation\n",
      "my_list = [1, 2, 3, 4, 5]\n",
      "\n",
      "# List with mixed data types\n",
      "fruits = ['apple', 'banana', 10, True]\n",
      "```\n",
      "\n",
      "**2. Accessing Elements:**\n",
      "\n",
      "```python\n",
      "# Accessing the first element\n",
      "first_element = my_list[0]\n",
      "\n",
      "# Accessing the last element\n",
      "last_element = my_list[-1]\n",
      "\n",
      "# Accessing an element at an index\n",
      "element_at_index = my_list[2]\n",
      "```\n",
      "\n",
      "**3. Iterating over Lists:**\n",
      "\n",
      "```python\n",
      "# Using a for loop\n",
      "for item in my_list:\n",
      "    print(item)\n",
      "\n",
      "# Using a while loop\n",
      "i = 0\n",
      "while i < len(my_list):\n",
      "    print(my_list[i])\n",
      "    i += 1\n",
      "```\n",
      "\n",
      "**4. Modifying Lists:**\n",
      "\n",
      "```python\n",
      "# Adding an element\n",
      "my_list.append(6)\n",
      "\n",
      "# Inserting an element at a specific index\n",
      "my_list.insert(2, 'hello')\n",
      "\n",
      "# Removing an element\n",
      "my_list\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "conversation.add_message(HumanMessage(content=\"How do I use lists in Python?\"))\n",
    "response = llm.predict(conversation)\n",
    "print(f\"Programming Response: {response.get_last().content}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Switch context to math tutor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Math Response: **5. Searching Lists:**\n",
      "\n",
      "```python\n",
      "# Checking if an element is in a list\n",
      "if 'apple' in fruits:\n",
      "    print('Apple is in the list.')\n",
      "\n",
      "# Finding the index of an element\n",
      "index = fruits.index('banana')\n",
      "```\n",
      "\n",
      "**6. Sorting Lists:**\n",
      "\n",
      "```python\n",
      "# Sorting in ascending order\n",
      "my_list.sort()\n",
      "\n",
      "# Sorting in descending order\n",
      "my_list.sort(reverse=True)\n",
      "```\n",
      "\n",
      "**7. Nested Lists:**\n",
      "\n",
      "```python\n",
      "# Creating a nested list\n",
      "nested_list = [[1, 2], [3, 4], [5, 6]]\n",
      "\n",
      "# Accessing elements of a nested list\n",
      "first_element = nested_list[0][0]\n",
      "```\n",
      "\n",
      "**Tips:**\n",
      "\n",
      "* Lists are mutable, which means you can modify them after creation.\n",
      "* The index of an element starts from 0.\n",
      "* Python lists support various data types, including numbers, strings, and objects.\n",
      "* List methods provide efficient ways to manipulate and analyze lists.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "conversation.system_context = SystemMessage(content=\"You are a mathematics tutor\")\n",
    "conversation.add_message(HumanMessage(content=\"What is algebra?\"))\n",
    "response = llm.predict(conversation)\n",
    "print(f\"Math Response: {response.get_last().content}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Switch to creative writing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Response: **1. Hook your reader:**\n",
      "\n",
      "* Start with a compelling action, mystery, or intriguing statement that captures the reader's attention.\n",
      "* Use vivid imagery and sensory details to create an immersive atmosphere.\n",
      "* Ask a question or introduce a mysterious element that piques the reader's curiosity.\n",
      "\n",
      "**2. Introduce the main characters:**\n",
      "\n",
      "* Briefly describe the protagonist's physical appearance, personality traits, and motivations.\n",
      "* Give the reader a sense of the character's background and goals.\n",
      "* Create an instant connection between the character and the reader.\n",
      "\n",
      "**3. Establish the setting:**\n",
      "\n",
      "* Create a vivid and immersive setting that enhances the story's atmosphere.\n",
      "* Use sensory details to transport the reader to the location.\n",
      "* Highlight any significant features or elements that will play a role in the story.\n",
      "\n",
      "**4. Present the conflict:**\n",
      "\n",
      "* Introduce the central conflict or problem that will drive the story.\n",
      "* This can be a physical obstacle, a moral dilemma, or an interpersonal conflict.\n",
      "* Clearly establish the stakes and consequences of the conflict.\n",
      "\n",
      "**5. Create tension and suspense:**\n",
      "\n",
      "* Use language that creates a sense of anticipation and excitement.\n",
      "* Hint at secrets, mysteries, or potential dangers.\n"
     ]
    }
   ],
   "source": [
    "conversation.system_context = SystemMessage(content=\"You are a creative writing coach\")\n",
    "conversation.add_message(HumanMessage(content=\"How do I write a story opening?\"))\n",
    "response = llm.predict(conversation)\n",
    "print(f\"Writing Response: {response.get_last().content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Context-Aware Responses**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create specialized contexts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "contexts = [\n",
    "    \"You are a technical expert who provides concise, technical answers\",\n",
    "    \"You are a teacher who explains concepts simply for beginners\",\n",
    "    \"You are a helpful assistant who gives practical, actionable advice\"\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test same question with different contexts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Context: You are a technical expert who provides concise, technical answers\n",
      "Response: Machine learning is the creation of algorithms that learn from data, enabling them to make predictions or decisions without explicit programming.\n",
      "\n",
      "Context: You are a teacher who explains concepts simply for beginners\n",
      "Response: Machine learning is training computers to learn from data, recognize patterns, and make accurate predictions or decisions without explicit programming.\n",
      "\n",
      "Context: You are a helpful assistant who gives practical, actionable advice\n",
      "Response: Machine learning is the ability of computer systems to learn and adapt from data without explicit programming instructions.\n"
     ]
    }
   ],
   "source": [
    "question = \"In one sentence define machine learning?\"\n",
    "\n",
    "for context in contexts:\n",
    "    conversation = MaxSystemContextConversation(\n",
    "        system_context=SystemMessage(content=context),\n",
    "        max_size=4\n",
    "    )\n",
    "    \n",
    "    conversation.add_message(HumanMessage(content=question))\n",
    "    response = llm.predict(conversation)\n",
    "    print(f\"\\nContext: {context}\")\n",
    "    print(f\"Response: {response.get_last().content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Conclusion**\n",
    "**We've explored how to:**\n",
    "\n",
    "We've learned how to:\n",
    "\n",
    "Integrate Groq LLM with context management\n",
    "\n",
    "Switch contexts dynamically\n",
    "\n",
    "Observe how different contexts affect LLM responses\n",
    "\n",
    "Manage system context for specialized interactions\n",
    "\n",
    "**Next, we'll learn about managing multi-turn conversations effectively.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **NOTEBOOK METADATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Dominion John \n",
      "GitHub Username: DOMINION-JOHN1\n",
      "Last Modified: 2024-11-04 10:26:50.496835\n",
      "Platform: Windows 11\n",
      "Python Version: 3.12.7 (tags/v3.12.7:0b05ead, Oct  1 2024, 03:06:41) [MSC v.1941 64 bit (AMD64)]\n",
      "Swarmauri Version: Swarmauri Version: 0.5.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import platform\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# Display author information\n",
    "author_name = \"Dominion John \" \n",
    "github_username = \"DOMINION-JOHN1\"  \n",
    "\n",
    "print(f\"Author: {author_name}\")\n",
    "print(f\"GitHub Username: {github_username}\")\n",
    "\n",
    "# Last modified datetime (file's metadata)\n",
    "notebook_file = \"Notebook_02_System_Context_Management.ipynb\"\n",
    "try:\n",
    "    last_modified_time = os.path.getmtime(notebook_file)\n",
    "    last_modified_datetime = datetime.fromtimestamp(last_modified_time)\n",
    "    print(f\"Last Modified: {last_modified_datetime}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not retrieve last modified datetime: {e}\")\n",
    "\n",
    "# Display platform, Python version, and Swarmauri version\n",
    "print(f\"Platform: {platform.system()} {platform.release()}\")\n",
    "print(f\"Python Version: {sys.version}\")\n",
    "\n",
    "import swarmauri\n",
    "\n",
    "try:\n",
    "    version = swarmauri.__version__\n",
    "except AttributeError:\n",
    "    version = f\"Swarmauri Version: 0.5.1\"\n",
    "\n",
    "print(f\"Swarmauri Version: {version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swarmauri-0.5.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
