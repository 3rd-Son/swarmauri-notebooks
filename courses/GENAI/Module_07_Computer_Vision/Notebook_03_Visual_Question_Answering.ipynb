{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd320ab2-614f-4da1-95e6-2581c91c567f",
   "metadata": {},
   "source": [
    "# Visual Question Answering (VQA) with FalAIVisionModel\n",
    "\n",
    "In this notebook, we explore Visual Question Answering (VQA), where the model interprets images to answer specific questions. VQA is valuable in applications like accessibility support, automated image captioning, and content understanding.\n",
    "\n",
    "This notebook will demonstrate:\n",
    "- Setting up VQA with `FalAIVisionModel`\n",
    "- Example VQA tasks with sample images\n",
    "- Exploring edge cases in VQA\n",
    "\n",
    "\n",
    "## Setting up the Model for VQA\n",
    "\n",
    "We will initialize the `FalAIVisionModel` and configure it to process images with question-based prompts, allowing it to interpret visual content and respond accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31bd0c24-d8df-460a-929c-5f9f58e66ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and initialize the model\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from swarmauri.llms.concrete.FalAIVisionModel import FalAIVisionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb71dba6-524c-456e-acec-1b4f92dd4c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FalAIVisionModel initialized for VQA.\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables and API key\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"FAL_KEY\")\n",
    "\n",
    "if API_KEY:\n",
    "    falai_vision_model = FalAIVisionModel(api_key=API_KEY)\n",
    "    print(\"FalAIVisionModel initialized for VQA.\")\n",
    "else:\n",
    "    print(\"API key not found. Please ensure it is set in the environment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ea96d2-9f89-4a9b-81e4-f5a10395974e",
   "metadata": {},
   "source": [
    "## Examples of VQA with Sample Images\n",
    "\n",
    "In this section, we process images with specific questions to demonstrate how the model can interpret and respond to visual data. We’ll use sample images like the Mona Lisa and famous landmarks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d9aa69a-be20-4b4e-a14a-020e437959fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image URLs and related questions\n",
    "image_url = \"https://llava-vl.github.io/static/images/monalisa.jpg\"\n",
    "questions = [\n",
    "    \"What is the subject of this painting?\",\n",
    "    \"Describe the main colors in the scene.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14856fe3-9212-4e7d-98ae-54ae79b46790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image URL: https://llava-vl.github.io/static/images/monalisa.jpg\n",
      "Q: What is the subject of this painting?\n",
      "A: The painting you've shown is the famous \"Mona Lisa\" by Leonardo da Vinci. It is one of the most recognized and celebrated works of art in the world. The subject of the painting is a woman with a subtle, enigmatic smile, set against a distant landscape. The painting is known\n",
      "\n",
      "Q: Describe the main colors in the scene.\n",
      "A: The image you've provided is the famous painting \"Mona Lisa\" by Leonardo da Vinci. The main colors in the scene are:\n",
      "\n",
      "- The skin tones of the subject, which are a soft blend of warm hues, including light beiges, pinks, and subtle yellows.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Process VQA for image and display results\n",
    "print(f\"\\nImage URL: {image_url}\")\n",
    "for question in questions:\n",
    "    try:\n",
    "        result = falai_vision_model.process_image(image_url=image_url, prompt=question)\n",
    "        print(f\"Q: {question}\\nA: {result}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315f2c61-7c89-4736-849b-c64f691a9a43",
   "metadata": {},
   "source": [
    "## Exploring Edge Cases in VQA\n",
    "\n",
    "To assess the model’s versatility, we’ll test it with more complex and ambiguous questions. This section helps identify how well the model handles challenging queries that require a deeper understanding or interpretation of the image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9444ed01-6496-42fc-9de0-6df6bcb99497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new image URL and complex questions for edge case testing\n",
    "edge_image_url = \"https://llava-vl.github.io/static/images/monalisa.jpg\"\n",
    "edge_questions = [\n",
    "    \"What emotions does the subject appear to show?\",\n",
    "    \"What could the background tell us about the setting?\",\n",
    "    \"Can you guess the era this painting is from?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "468260c6-aa20-479b-904a-d0b71b59dea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Edge Case Testing with Image URL: https://llava-vl.github.io/static/images/monalisa.jpg\n",
      "Q: What emotions does the subject appear to show?\n",
      "A: The subject in the image appears to be showing a serene and contemplative emotion. The slight smile and the direct gaze give the impression of a calm and composed individual. The overall expression is often referred to as the \"Mona Lisa smile,\" which is characterized by a subtle, enigmatic quality that has been\n",
      "\n",
      "Q: What could the background tell us about the setting?\n",
      "A: The background of the image features a landscape with a river, trees, and a distant view of a city or town. This suggests that the setting is likely an urban or semi-urban area with a natural environment nearby. The presence of a river indicates that the location might be near a water source, which could have been\n",
      "\n",
      "Q: Can you guess the era this painting is from?\n",
      "A: The painting you've shown is the Mona Lisa, which is a famous work by Leonardo da Vinci. It was painted during the Renaissance, which was a period of cultural, artistic, and scientific rebirth in Europe that spanned roughly from the 14th to the 17th century. The\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Process VQA with edge case questions\n",
    "print(f\"\\nEdge Case Testing with Image URL: {edge_image_url}\")\n",
    "for question in edge_questions:\n",
    "    try:\n",
    "        result = falai_vision_model.process_image(image_url=edge_image_url, prompt=question)\n",
    "        print(f\"Q: {question}\\nA: {result}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1c34d4-331c-4e2f-a9da-dbda4c180ff9",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this notebook, we demonstrated the capabilities of `FalAIVisionModel` in Visual Question Answering (VQA):\n",
    "- Using specific questions to understand visual content\n",
    "- Handling both straightforward and complex queries\n",
    "\n",
    "VQA holds potential for numerous real-world applications, enhancing accessibility, enriching user interaction, and supporting content moderation tasks.\n",
    "Advances in VQA models can further drive these applications, enabling more interactive and intelligent AI systems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a8ee36-7c8b-4f80-934a-156e954e02cf",
   "metadata": {},
   "source": [
    "# Notebook Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62493b1d-47d9-4cac-b73c-c0e5ea08a8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Huzaifa Irshad\n",
      "GitHub Username: irshadhuzaifa\n",
      "Last Modified: 2024-11-04 20:38:35.037660\n",
      "Platform: Windows 11\n",
      "Python Version: 3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 13:17:27) [MSC v.1929 64 bit (AMD64)]\n",
      "Swarmauri Version: Swarmauri Version: 0.5.1\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# Display author information\n",
    "author_name = \"Huzaifa Irshad\" \n",
    "github_username = \"irshadhuzaifa\"  \n",
    "\n",
    "print(f\"Author: {author_name}\")\n",
    "print(f\"GitHub Username: {github_username}\")\n",
    "\n",
    "# Last modified datetime (file's metadata)\n",
    "notebook_file = \"Notebook_03_Visual_Question_Answering.ipynb\"\n",
    "try:\n",
    "    last_modified_time = os.path.getmtime(notebook_file)\n",
    "    last_modified_datetime = datetime.fromtimestamp(last_modified_time)\n",
    "    print(f\"Last Modified: {last_modified_datetime}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not retrieve last modified datetime: {e}\")\n",
    "\n",
    "# Display platform, Python version, and Swarmauri version\n",
    "print(f\"Platform: {platform.system()} {platform.release()}\")\n",
    "print(f\"Python Version: {sys.version}\")\n",
    "\n",
    "import swarmauri\n",
    "\n",
    "try:\n",
    "    version = swarmauri.__version__\n",
    "except AttributeError:\n",
    "    version = f\"Swarmauri Version: 0.5.1\"\n",
    "\n",
    "print(f\"Swarmauri Version: {version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8a0297-7076-4681-90e8-0c764fffde15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swarmauri(0.5.1)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
