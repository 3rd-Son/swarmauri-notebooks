{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7de9669-dce2-402d-993c-d85d451ed7a2",
   "metadata": {},
   "source": [
    "# Image Analysis Applications with FalAIVisionModel\n",
    "\n",
    "In this notebook, we explore diverse applications of image analysis, focusing on areas like content moderation, tagging, and descriptive analytics. These applications have become essential across multiple fields:\n",
    "- **Healthcare:** Assisting in medical image diagnostics and treatment planning.\n",
    "- **Retail:** Enabling automatic product tagging and recommendation.\n",
    "- **Social Media:** Supporting content moderation, tagging, and enhanced user engagement.\n",
    "\n",
    "By the end of this notebook, we will demonstrate how `FalAIVisionModel` can be utilized for these use cases.\n",
    "\n",
    "## Content Moderation and Tagging\n",
    "\n",
    "Image moderation and tagging are critical in applications that require filtering or organizing visual content. Here, we use `FalAIVisionModel` to classify images, identifying sensitive content and general categories like \"portrait\" or \"landscape.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99854647-956a-4bb1-8e6a-d6e26a83715d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from swarmauri.llms.concrete.FalAIVisionModel import FalAIVisionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18e3a251-d0d8-4863-9a53-eaccb23933fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables and API key\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"FAL_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6afac946-860e-4cbb-b76a-f34adc017950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "falai_vision_model = FalAIVisionModel(api_key=API_KEY) if API_KEY else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56ef33ac-3252-400e-90d4-620278d183f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of content moderation and tagging\n",
    "image_url_moderation = \"https://llava-vl.github.io/static/images/monalisa.jpg\"\n",
    "moderation_prompt = \"Identify content tags and detect any sensitive content in this image.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04e32f94-1dd4-4c54-8913-a5da42af20b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moderation Result for image:\n",
      "The image you've provided is the famous painting \"Mona Lisa\" by Leonardo da Vinci. The content tags for this image could include:\n",
      "\n",
      "1. Art\n",
      "2. Painting\n",
      "3. Renaissance\n",
      "4. Portrait\n",
      "5. Female figure\n",
      "6. Smiling\n",
      "7. Land\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run content moderation\n",
    "try:\n",
    "    moderation_result = falai_vision_model.process_image(image_url=image_url_moderation, prompt=moderation_prompt)\n",
    "    print(f\"Moderation Result for image:\\n{moderation_result}\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during moderation: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515a3224-7f55-4ef1-86df-cce6f9efe897",
   "metadata": {},
   "source": [
    "## Image Captioning and Descriptions\n",
    "\n",
    "Descriptive analytics provides contextual information about images, enabling applications such as automated image captioning. In this example, we prompt the model to generate captions for a landscape scene.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9387c51a-3a16-441e-a993-9bcf3dae707b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for generating captions for an image\n",
    "image_url_captioning = \"https://llava-vl.github.io/static/images/monalisa.jpg\"\n",
    "caption_prompt = \"Describe the image in detail.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a8ade53-c8ed-4580-9c12-71d90bbd3663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caption for image:\n",
      "The image is a digital rendering of the famous painting \"Mona Lisa\" by Leonardo da Vinci. The painting is characterized by its soft, atmospheric perspective and the subtle modeling of forms and figures. The subject, a woman, is depicted with a slight smile and her gaze directed towards the viewer. The background features\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate caption\n",
    "try:\n",
    "    caption_result = falai_vision_model.process_image(image_url=image_url_captioning, prompt=caption_prompt)\n",
    "    print(f\"Caption for image:\\n{caption_result}\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during captioning: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eada40c-d867-433d-98d3-061ea8f1a2a2",
   "metadata": {},
   "source": [
    "## Batch Processing for Large Datasets\n",
    "\n",
    "Batch processing is crucial for applications needing to analyze multiple images at once. Here, we demonstrate batch processing by extracting tags, descriptions, or categories for a set of images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7e3a3e2-c44d-42a7-81be-3ddc59ccdcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define multiple images for batch processing\n",
    "image_urls = [\n",
    "    \"https://llava-vl.github.io/static/images/monalisa.jpg\",\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/6/6d/Good_Food_Display_-_NCI_Visuals_Online.jpg\",\n",
    "]\n",
    "batch_prompt = \"Provide a description and categorize this image.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "392d45bf-7e9b-4e36-8d85-bc239f434bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch processing of images\n",
    "batch_results = []\n",
    "for image_url in image_urls:\n",
    "    try:\n",
    "        result = falai_vision_model.process_image(image_url=image_url, prompt=batch_prompt)\n",
    "        batch_results.append({\"image_url\": image_url, \"result\": result})\n",
    "    except Exception as e:\n",
    "        batch_results.append({\"image_url\": image_url, \"error\": str(e)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb716359-8dd5-4c89-941a-f96414e5ae02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image URL: https://llava-vl.github.io/static/images/monalisa.jpg\n",
      "Result: The image you've provided is a well-known painting of the Mona Lisa, a portrait of a woman with a serene and enigmatic expression. The painting is characterized by its soft blending of colors, atmospheric perspective, and the subtle modeling of forms and figures. The background is a distant, imaginary landscape\n",
      "\n",
      "Image URL: https://upload.wikimedia.org/wikipedia/commons/6/6d/Good_Food_Display_-_NCI_Visuals_Online.jpg\n",
      "Result: The image depicts a vibrant and colorful assortment of food items, arranged in an appealing and appetizing manner. It appears to be a still life photograph, showcasing a variety of fresh produce and other foodstuffs.\n",
      "\n",
      "From the top left, there's a jar of what looks like nuts or seeds, followed by\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display batch results\n",
    "for item in batch_results:\n",
    "    print(f\"Image URL: {item['image_url']}\")\n",
    "    print(f\"Result: {item.get('result', 'Error: ' + item.get('error', 'Unknown error'))}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9704736-0bf7-4c6a-8130-9bd568278a6d",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this notebook, we demonstrated multiple applications of image analysis using `FalAIVisionModel`:\n",
    "- **Content Moderation and Tagging:** Enabling safe and organized visual content.\n",
    "- **Image Captioning:** Providing automated, descriptive captions for visual data.\n",
    "- **Batch Processing:** Analyzing large datasets efficiently for tags, descriptions, and categories.\n",
    "\n",
    "These techniques are essential in automating visual insights, helping scale content moderation, enhance user experience, and support analytical applications across fields like healthcare, retail, and social media.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe11f615-3ca7-4477-be40-3aa3d460f3cd",
   "metadata": {},
   "source": [
    "# Notebook Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ebb207e-3af6-43e9-b687-e2a3f2b879cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Huzaifa Irshad\n",
      "GitHub Username: irshadhuzaifa\n",
      "Last Modified: 2024-11-04 20:36:28.305533\n",
      "Platform: Windows 11\n",
      "Python Version: 3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 13:17:27) [MSC v.1929 64 bit (AMD64)]\n",
      "Swarmauri Version: Swarmauri Version: 0.5.1\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# Display author information\n",
    "author_name = \"Huzaifa Irshad\" \n",
    "github_username = \"irshadhuzaifa\"  \n",
    "\n",
    "print(f\"Author: {author_name}\")\n",
    "print(f\"GitHub Username: {github_username}\")\n",
    "\n",
    "# Last modified datetime (file's metadata)\n",
    "notebook_file = \"Notebook_04_Image_Analysis_Applications.ipynb\"\n",
    "try:\n",
    "    last_modified_time = os.path.getmtime(notebook_file)\n",
    "    last_modified_datetime = datetime.fromtimestamp(last_modified_time)\n",
    "    print(f\"Last Modified: {last_modified_datetime}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not retrieve last modified datetime: {e}\")\n",
    "\n",
    "# Display platform, Python version, and Swarmauri version\n",
    "print(f\"Platform: {platform.system()} {platform.release()}\")\n",
    "print(f\"Python Version: {sys.version}\")\n",
    "\n",
    "import swarmauri\n",
    "\n",
    "try:\n",
    "    version = swarmauri.__version__\n",
    "except AttributeError:\n",
    "    version = f\"Swarmauri Version: 0.5.1\"\n",
    "\n",
    "print(f\"Swarmauri Version: {version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57539d05-9299-4d3f-b790-37bd179c734e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swarmauri(0.5.1)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
