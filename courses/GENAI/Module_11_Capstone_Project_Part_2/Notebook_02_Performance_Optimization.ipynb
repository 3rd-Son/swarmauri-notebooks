{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04666001-a4ed-4ddf-a129-debe574db9bc",
   "metadata": {},
   "source": [
    "# Multimodal Chatbot System\n",
    "\n",
    "### Purpose\n",
    "This notebook integrates and validates different AI components (text, image, and audio) into a unified multimodal chatbot system. The chatbot can perform text generation, image generation, audio generation, and computer vision tasks. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd69a30-362b-4eb6-b0a6-2a627abd0532",
   "metadata": {},
   "source": [
    "### **Project Setup**\n",
    "1. Load the necessary libraries.\n",
    "2. Ensure environment variables for API keys are properly set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c90716fd-2337-401d-ad80-6780b1c913d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from swarmauri.utils.base64_to_img_url import base64_to_img_url\n",
    "from swarmauri.llms.concrete.FalAIVisionModel import FalAIVisionModel\n",
    "from swarmauri.llms.concrete.OpenAIAudioTTS import OpenAIAudioTTS\n",
    "from swarmauri.llms.concrete.OpenAIModel import OpenAIModel as LLM\n",
    "from swarmauri.conversations.concrete.Conversation import Conversation\n",
    "from swarmauri.messages.concrete.HumanMessage import HumanMessage\n",
    "from swarmauri.llms.concrete.DeepInfraImgGenModel import DeepInfraImgGenModel\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Fetch API keys\n",
    "DEEPINFRA_API_KEY = os.getenv(\"DEEPINFRA_API_KEY\")\n",
    "IMGBB_API_KEY = os.getenv(\"IMGBB_API_KEY\")\n",
    "API_KEY = os.getenv(\"FAL_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Initialize models\n",
    "llm = LLM(api_key=OPENAI_API_KEY)\n",
    "llm_img_gen = DeepInfraImgGenModel(api_key=DEEPINFRA_API_KEY)\n",
    "falai_vision_model = FalAIVisionModel(api_key=API_KEY) if API_KEY else None\n",
    "tts = OpenAIAudioTTS(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Output directory for audio\n",
    "output_dir = Path(\"output\")\n",
    "output_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022c35fe-e8cb-4e0c-8428-69cd21271e3f",
   "metadata": {},
   "source": [
    "## Function `multimodal_chatbot` to handle various user inputs.\n",
    "\n",
    "This function consolidates all tasks, enabling the chatbot to handle multimodal inputs and outputs in a seamless, user-friendly manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "622413a8-32b5-4129-ac40-ae20efb72a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to handle text, image, and audio inputs and outputs\n",
    "def multimodal_chatbot(input_data, mode=\"text\", voice=\"alloy\", model=\"tts-1\", output_filename=\"output.mp3\"):\n",
    "    \"\"\"\n",
    "    Multimodal Chatbot Function\n",
    "    \n",
    "    Parameters:\n",
    "    - input_data (str): User's input, can be text or image URL.\n",
    "    - mode (str): The type of task ('text', 'image_gen', 'audio', 'vision'). Default is 'text'.\n",
    "    - voice (str): Voice for TTS. Default is 'alloy'.\n",
    "    - model (str): TTS model. Default is 'tts-1'.\n",
    "    - output_filename (str): Filename for the generated audio. Default is 'output.mp3'.\n",
    "    \n",
    "    Returns:\n",
    "    - str or None: Text response, Image URL, or audio path based on mode.\n",
    "    \"\"\"\n",
    "    if mode == \"text\":\n",
    "        # Generate text response\n",
    "        conversation = Conversation()\n",
    "        conversation.add_message(HumanMessage(content=input_data))\n",
    "        llm.predict(conversation=conversation)\n",
    "        response = conversation.get_last().content\n",
    "        print(f\"Text Response: {response}\")\n",
    "        return response\n",
    "    \n",
    "    elif mode == \"image_gen\":\n",
    "        # Generate image from text\n",
    "        conversation = Conversation()\n",
    "        conversation.add_message(HumanMessage(content=input_data))\n",
    "        llm.predict(conversation=conversation)\n",
    "        detailed_description = conversation.get_last().content\n",
    "        image_base64 = llm_img_gen.generate_image_base64(detailed_description)\n",
    "        try:\n",
    "            image_url = base64_to_img_url(image_base64, IMGBB_API_KEY)\n",
    "            print(f\"Generated Image URL: {image_url}\")\n",
    "            return image_url\n",
    "        except Exception as e:\n",
    "            print(f\"Error uploading the image: {e}\")\n",
    "            return None\n",
    "    \n",
    "    elif mode == \"audio\":\n",
    "        # Generate audio from text\n",
    "        tts.name = model\n",
    "        tts.voice = voice\n",
    "        output_path = output_dir / output_filename\n",
    "        tts.predict(text=input_data, audio_path=str(output_path))\n",
    "        print(f\"Generated audio saved to: {output_path}\")\n",
    "        return str(output_path)\n",
    "    \n",
    "    elif mode == \"vision\":\n",
    "        # Analyze image using computer vision\n",
    "        try:\n",
    "            result = falai_vision_model.process_image(image_url=input_data, prompt=\"Describe the content of this image.\")\n",
    "            print(f\"Image Analysis Result: {result}\")\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image: {e}\")\n",
    "            return None\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid mode. Choose from 'text', 'image_gen', 'audio', or 'vision'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344f9ff9-6b3e-4ff8-9243-5dcc43bdd371",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecc25868-9b64-429d-9f64-5f2becbcff53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Response: Dr. Emily Roberts had always been passionate about astronomy. She spent countless nights gazing up at the stars, dreaming of the mysteries that lay beyond our solar system. So when she was given the opportunity to lead a team of researchers on a mission to discover new planets, she jumped at the chance.\n",
      "\n",
      "Equipped with the latest technology and a team of brilliant scientists, Dr. Roberts set out on their journey into the vast unknown. For months, they scanned the skies, analyzing data and searching for any signs of distant planets.\n",
      "\n",
      "And then, one fateful night, they made a groundbreaking discovery. Hidden among the sea of stars was a new solar system, unlike anything they had ever seen before. It was home to not just one, but three habitable planets, each with the potential to support life.\n",
      "\n",
      "Dr. Roberts and her team were elated. They had unlocked a new chapter in the history of space exploration, and their names would go down in the annals of science. But more than that, they had discovered a glimmer of hope in the darkness of the universe. The possibility that somewhere out there, beyond our wildest dreams, life could be thriving on these distant worlds.\n",
      "\n",
      "And so, Dr. Roberts continued her work, searching the cosmos for more planets to\n"
     ]
    }
   ],
   "source": [
    "# 1. Text Generation\n",
    "example_prompt = \"Tell me a short story about a scientist discovering new planets.\"\n",
    "text_response = multimodal_chatbot(input_data=example_prompt, mode=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ea0cfa4-9c0c-46b6-93b4-c87d7fc7c2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Image URL: https://i.ibb.co/CMGBvtf/c6972ed60730.jpg\n"
     ]
    }
   ],
   "source": [
    "# 2. Image Generation\n",
    "image_prompt = \"A futuristic city skyline at night with neon lights and flying cars.\"\n",
    "image_url = multimodal_chatbot(input_data=image_prompt, mode=\"image_gen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "331061e2-29fb-4158-991e-35e7d363aabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated audio saved to: output\\sample_output.mp3\n"
     ]
    }
   ],
   "source": [
    "# 3. Audio Generation\n",
    "sample_text = \"Welcome to the text-to-speech demonstration.\"\n",
    "audio_path = multimodal_chatbot(input_data=sample_text, mode=\"audio\", voice=\"shimmer\", output_filename=\"sample_output.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c11448f-1e89-488a-9a5a-6c58fc9d2a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Analysis Result: The image you've provided is the famous painting known as the Mona Lisa. It is a portrait of a woman with a serene and enigmatic expression. The background features a distant, imaginary landscape, which is characteristic of Leonardo da Vinci's style. The painting is renowned for its use of\n"
     ]
    }
   ],
   "source": [
    "# 4. Computer Vision\n",
    "image_url = \"https://llava-vl.github.io/static/images/monalisa.jpg\"\n",
    "vision_response = multimodal_chatbot(input_data=image_url, mode=\"vision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7818af-2cb2-487c-a61f-d491d097b450",
   "metadata": {},
   "source": [
    "# Notebook Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc7c1ce5-91a9-4572-b862-2c3de01db26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Huzaifa Irshad\n",
      "GitHub Username: irshadhuzaifa\n",
      "Last Modified: 2024-11-07 12:58:51.580808\n",
      "Platform: Windows 11\n",
      "Python Version: 3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 13:17:27) [MSC v.1929 64 bit (AMD64)]\n",
      "Swarmauri Version: Swarmauri Version: 0.5.1\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# Display author information\n",
    "author_name = \"Huzaifa Irshad\" \n",
    "github_username = \"irshadhuzaifa\"  \n",
    "\n",
    "print(f\"Author: {author_name}\")\n",
    "print(f\"GitHub Username: {github_username}\")\n",
    "\n",
    "# Last modified datetime (file's metadata)\n",
    "notebook_file = \"Notebook_02_Performance_Optimization.ipynb\"\n",
    "try:\n",
    "    last_modified_time = os.path.getmtime(notebook_file)\n",
    "    last_modified_datetime = datetime.fromtimestamp(last_modified_time)\n",
    "    print(f\"Last Modified: {last_modified_datetime}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not retrieve last modified datetime: {e}\")\n",
    "\n",
    "# Display platform, Python version, and Swarmauri version\n",
    "print(f\"Platform: {platform.system()} {platform.release()}\")\n",
    "print(f\"Python Version: {sys.version}\")\n",
    "\n",
    "import swarmauri\n",
    "\n",
    "try:\n",
    "    version = swarmauri.__version__\n",
    "except AttributeError:\n",
    "    version = f\"Swarmauri Version: 0.5.1\"\n",
    "\n",
    "print(f\"Swarmauri Version: {version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a73bde9-ffd0-4537-b718-a3283c4f3269",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swarmauri(0.5.1)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
