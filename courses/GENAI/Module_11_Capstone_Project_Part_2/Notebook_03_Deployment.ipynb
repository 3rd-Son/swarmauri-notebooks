{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e0a1dfc-ddc5-447d-bbc7-c8f0f42d7948",
   "metadata": {},
   "source": [
    "## Import Necessary Libraries and Load Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "882051dd-c799-43c3-9b58-a119815d31a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from swarmauri.utils.base64_to_img_url import base64_to_img_url\n",
    "from swarmauri.llms.concrete.FalAIVisionModel import FalAIVisionModel\n",
    "from swarmauri.llms.concrete.OpenAIAudioTTS import OpenAIAudioTTS\n",
    "from swarmauri.llms.concrete.OpenAIModel import OpenAIModel as LLM\n",
    "from swarmauri.conversations.concrete.Conversation import Conversation\n",
    "from swarmauri.messages.concrete.HumanMessage import HumanMessage\n",
    "from swarmauri.llms.concrete.DeepInfraImgGenModel import DeepInfraImgGenModel\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "DEEPINFRA_API_KEY = os.getenv(\"DEEPINFRA_API_KEY\")\n",
    "IMGBB_API_KEY = os.getenv(\"IMGBB_API_KEY\")\n",
    "FAL_KEY = os.getenv(\"FAL_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "# Initialize models\n",
    "llm = LLM(api_key=OPENAI_API_KEY)\n",
    "llm_img_gen = DeepInfraImgGenModel(api_key=DEEPINFRA_API_KEY)\n",
    "falai_vision_model = FalAIVisionModel(api_key=FAL_KEY) if FAL_KEY else None\n",
    "tts = OpenAIAudioTTS(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Output directory for audio\n",
    "output_dir = Path(\"output\")\n",
    "output_dir.mkdir(exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bd0c39-0b26-4032-97dd-bf6373069124",
   "metadata": {},
   "source": [
    "## Multimodal Chatbot Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1efee5ae-912c-4a6f-bec5-9c453bc9d640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multimodal_chatbot(input_text, mode=\"text\", system_context=\"Default system context\", model_name=\"tts-1\"):\n",
    "    \"\"\"\n",
    "    Multimodal chatbot function handling different modes of interaction.\n",
    "\n",
    "    Parameters:\n",
    "    - input_text (str): User's input.\n",
    "    - mode (str): Mode of interaction ('text', 'image_gen', 'audio', 'vision').\n",
    "    - system_context (str): Additional context.\n",
    "    - model_name (str): Model for text-to-speech.\n",
    "    \n",
    "    Returns:\n",
    "    - Response based on mode.\n",
    "    \"\"\"\n",
    "    if mode == \"text\":\n",
    "        conversation = Conversation()\n",
    "        conversation.add_message(HumanMessage(content=system_context + \"\\n\" + input_text))\n",
    "        llm.predict(conversation=conversation)\n",
    "        return conversation.get_last().content\n",
    "\n",
    "    elif mode == \"image_gen\":\n",
    "        conversation = Conversation()\n",
    "        conversation.add_message(HumanMessage(content=input_text))\n",
    "        llm.predict(conversation=conversation)\n",
    "        detailed_description = conversation.get_last().content\n",
    "        image_base64 = llm_img_gen.generate_image_base64(detailed_description)\n",
    "        image_url = base64_to_img_url(image_base64, IMGBB_API_KEY)\n",
    "        return f\"Generated Image: {image_url}\"\n",
    "\n",
    "    elif mode == \"audio\":\n",
    "        tts.name = model_name\n",
    "        tts.voice = \"alloy\"\n",
    "        output_path = output_dir / \"output.mp3\"\n",
    "        tts.predict(text=input_text, audio_path=str(output_path))\n",
    "        return f\"Audio saved: {str(output_path)}\"\n",
    "\n",
    "    elif mode == \"vision\":\n",
    "        result = falai_vision_model.process_image(image_url=input_text, prompt=\"Describe this image.\")\n",
    "        return result\n",
    "    else:\n",
    "        return \"Invalid mode selected.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1d98e4-ea8d-419e-888d-879c61dc445d",
   "metadata": {},
   "source": [
    "## Build Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99d967d2-5a8f-4324-b2f5-28219310832e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c13648ad-e4b7-43e0-9c75-90eabd639571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define Gradio interface\n",
    "def gradio_interface(user_input, mode, system_context, model_name):\n",
    "    return multimodal_chatbot(user_input, mode=mode, system_context=system_context, model_name=model_name)\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Multimodal Chatbot\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        user_input = gr.Textbox(label=\"Input\", placeholder=\"Type your text or image URL here...\")\n",
    "        mode = gr.Dropdown(choices=[\"text\", \"image_gen\", \"audio\", \"vision\"], label=\"Mode\", value=\"text\")\n",
    "    \n",
    "    system_context = gr.Textbox(label=\"System Context\", value=\"Default system context\", placeholder=\"Add any context...\")\n",
    "    model_name = gr.Textbox(label=\"TTS Model Name (for audio)\", value=\"tts-1\")\n",
    "    \n",
    "    output = gr.Textbox(label=\"Output\", lines=10, interactive=True)\n",
    "    \n",
    "    submit_btn = gr.Button(\"Submit\")\n",
    "    submit_btn.click(gradio_interface, inputs=[user_input, mode, system_context, model_name], outputs=output)\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a110750-fb48-4cd7-8f34-764d493106fd",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- Gradio simplifies building user-friendly UIs for your multimodal chatbot.\n",
    "- Users can interact with the chatbot for different modes (text, image, audio, vision).\n",
    "- This interface is easily extendable and deployable locally or online."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e0855f-d4df-4c0d-90f6-43a7aea13d6c",
   "metadata": {},
   "source": [
    "# Notebook Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fbc000e-49e9-4198-8090-3d1e7cb3b1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Huzaifa Irshad\n",
      "GitHub Username: irshadhuzaifa\n",
      "Last Modified: 2024-11-07 13:27:24.813063\n",
      "Platform: Windows 11\n",
      "Python Version: 3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 13:17:27) [MSC v.1929 64 bit (AMD64)]\n",
      "Swarmauri Version: Swarmauri Version: 0.5.1\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# Display author information\n",
    "author_name = \"Huzaifa Irshad\" \n",
    "github_username = \"irshadhuzaifa\"  \n",
    "\n",
    "print(f\"Author: {author_name}\")\n",
    "print(f\"GitHub Username: {github_username}\")\n",
    "\n",
    "# Last modified datetime (file's metadata)\n",
    "notebook_file = \"Notebook_03_Deployment.ipynb\"\n",
    "try:\n",
    "    last_modified_time = os.path.getmtime(notebook_file)\n",
    "    last_modified_datetime = datetime.fromtimestamp(last_modified_time)\n",
    "    print(f\"Last Modified: {last_modified_datetime}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not retrieve last modified datetime: {e}\")\n",
    "\n",
    "# Display platform, Python version, and Swarmauri version\n",
    "print(f\"Platform: {platform.system()} {platform.release()}\")\n",
    "print(f\"Python Version: {sys.version}\")\n",
    "\n",
    "import swarmauri\n",
    "\n",
    "try:\n",
    "    version = swarmauri.__version__\n",
    "except AttributeError:\n",
    "    version = f\"Swarmauri Version: 0.5.1\"\n",
    "\n",
    "print(f\"Swarmauri Version: {version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e4e99c-f670-4c65-9a9a-6f11e032dca1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swarmauri(0.5.1)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
